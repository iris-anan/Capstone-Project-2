{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Tweet Data from Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticating Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import sys\n",
    "import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "consumer_key = \"xzUQDPt5xWi2vnFHkEPnNbox1\"\n",
    "consumer_secret = \"HfDQSgcX0h2A6xHZhfXOYyc6sXkNEnY52RqvL3kPvGIjywQLPV\"\n",
    "\n",
    "access_token = \"1126929832548257792-EJn3G8R0q7iDOX75SUAflrMT6OKT6F\"\n",
    "access_token_secret = \"UhL3ErCAPxd73LLrqujOgPTQHjWfqQGKHxwyFolPnt3ou\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to SQLite to Build Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('capstone2.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(name, col_details):\n",
    "    cursor.execute('CREATE TABLE IF NOT EXISTS ' + name + '(' + col_details + ')')\n",
    "    \n",
    "def data_entry(name, values):\n",
    "    cursor.execute('INSERT INTO ' + name + ' VALUES' + '(' + values + ')')\n",
    "    \n",
    "import re\n",
    "pat = r'RT'\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "pat3 = r'([^0-9A-Za-z \\t])'\n",
    "combined_pat = r'|'.join((pat, pat1, pat2, pat3))\n",
    "def tweet_cleaner(text):\n",
    "    stripped = re.sub(combined_pat, '', text)\n",
    "    return stripped\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    for key in list(score.keys()):\n",
    "        new_key = key + '_sent'\n",
    "        score[key + '_sent'] = score.pop(key)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've made 2 key functions here that would help with the sentiment analysis.\n",
    "\n",
    "The function *clean_tweet* was created using the re (regular expression) package that removes special characters and hyperlinks from the tweet so that it can be analyzed more accurately.\n",
    "\n",
    "The sentiment analyzer used is called VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created Necessary Tables in Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['netflix_tweets', 'disney_tweets', 'amazon_tweets', 'google_tweets']\n",
    "for table in tables:\n",
    "    create_table(table, \n",
    "             'created_at DATETIME, tweet VARCHAR(200), follower_count INT, neg_sent FLOAT, neu_sent FLOAT, pos_sent FLOAT, compound_sent FLOAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Twitter API Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrote query to select appropriate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' OR '\n",
    "netflix = '@Netflix OR $NFLX OR Netflix'\n",
    "disney = ['@Disney', '@ESPN', '@ABCnetwork', '@Pixar', '@Marvel', '$DIS']\n",
    "disney = s.join(disney)\n",
    "amazon = ['@Amazon', '@PrimeVideo', '@awscloud', '@TwitchPrime', '@Alexa', '@WholeFoods', '$AMZN']\n",
    "amazon = s.join(amazon)\n",
    "google = ['@Google', '@Android', '@Waymo', '$GOOGL']\n",
    "google = s.join(google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting the tweets from Twitter API into local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.search, q= amazon, lang=\"en\", since_id=\"2019-06-15\",  until = \"2019-06-16\", tweet_mode='extended').items():\n",
    "    follower_count = tweet.user.followers_count\n",
    "    data = {'created_at': tweet.created_at.date(), 'tweet': tweet.full_text, 'follower_count': follower_count}\n",
    "    data.update(sentiment_analyzer_scores(tweet_cleaner(tweet.full_text)))\n",
    "    columns = ', '.join(data.keys())\n",
    "    placeholders = ':'+', :'.join(data.keys())\n",
    "    query = 'INSERT INTO amazon_tweets (%s) VALUES (%s)' % (columns, placeholders)\n",
    "    cursor.execute(query, data)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Daily Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>1122.55</td>\n",
       "      <td>1178.30</td>\n",
       "      <td>1121.40</td>\n",
       "      <td>1170.80</td>\n",
       "      <td>2965117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>1171.84</td>\n",
       "      <td>1194.16</td>\n",
       "      <td>1168.45</td>\n",
       "      <td>1184.50</td>\n",
       "      <td>1765388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>1175.83</td>\n",
       "      <td>1186.29</td>\n",
       "      <td>1166.42</td>\n",
       "      <td>1168.78</td>\n",
       "      <td>1268050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>1153.00</td>\n",
       "      <td>1153.00</td>\n",
       "      <td>1138.13</td>\n",
       "      <td>1144.66</td>\n",
       "      <td>1530126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>1154.48</td>\n",
       "      <td>1158.00</td>\n",
       "      <td>1143.31</td>\n",
       "      <td>1154.44</td>\n",
       "      <td>1028248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>1151.25</td>\n",
       "      <td>1163.78</td>\n",
       "      <td>1151.00</td>\n",
       "      <td>1155.85</td>\n",
       "      <td>941279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>1146.07</td>\n",
       "      <td>1150.05</td>\n",
       "      <td>1133.16</td>\n",
       "      <td>1145.34</td>\n",
       "      <td>1260657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>1152.00</td>\n",
       "      <td>1154.36</td>\n",
       "      <td>1136.71</td>\n",
       "      <td>1138.61</td>\n",
       "      <td>927651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>1141.48</td>\n",
       "      <td>1156.49</td>\n",
       "      <td>1138.67</td>\n",
       "      <td>1139.56</td>\n",
       "      <td>1047554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>1132.70</td>\n",
       "      <td>1135.00</td>\n",
       "      <td>1111.95</td>\n",
       "      <td>1119.94</td>\n",
       "      <td>1811510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>1120.15</td>\n",
       "      <td>1126.80</td>\n",
       "      <td>1115.90</td>\n",
       "      <td>1121.41</td>\n",
       "      <td>904419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1105.64</td>\n",
       "      <td>1113.40</td>\n",
       "      <td>1103.35</td>\n",
       "      <td>1106.50</td>\n",
       "      <td>1579481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>1066.93</td>\n",
       "      <td>1067.00</td>\n",
       "      <td>1027.03</td>\n",
       "      <td>1038.74</td>\n",
       "      <td>4844480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>1044.49</td>\n",
       "      <td>1058.44</td>\n",
       "      <td>1036.03</td>\n",
       "      <td>1054.49</td>\n",
       "      <td>3025564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>1055.00</td>\n",
       "      <td>1056.81</td>\n",
       "      <td>1033.00</td>\n",
       "      <td>1044.64</td>\n",
       "      <td>2349436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>1046.21</td>\n",
       "      <td>1050.00</td>\n",
       "      <td>1035.51</td>\n",
       "      <td>1047.76</td>\n",
       "      <td>1451026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>1054.28</td>\n",
       "      <td>1073.43</td>\n",
       "      <td>1051.15</td>\n",
       "      <td>1068.37</td>\n",
       "      <td>2191357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>1077.00</td>\n",
       "      <td>1094.84</td>\n",
       "      <td>1075.28</td>\n",
       "      <td>1082.76</td>\n",
       "      <td>1423928.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     open     high      low    close     volume\n",
       "0   2019-05-15  1122.55  1178.30  1121.40  1170.80  2965117.0\n",
       "1   2019-05-16  1171.84  1194.16  1168.45  1184.50  1765388.0\n",
       "2   2019-05-17  1175.83  1186.29  1166.42  1168.78  1268050.0\n",
       "3   2019-05-20  1153.00  1153.00  1138.13  1144.66  1530126.0\n",
       "4   2019-05-21  1154.48  1158.00  1143.31  1154.44  1028248.0\n",
       "5   2019-05-22  1151.25  1163.78  1151.00  1155.85   941279.0\n",
       "6   2019-05-23  1146.07  1150.05  1133.16  1145.34  1260657.0\n",
       "7   2019-05-24  1152.00  1154.36  1136.71  1138.61   927651.0\n",
       "8   2019-05-28  1141.48  1156.49  1138.67  1139.56  1047554.0\n",
       "9   2019-05-29  1132.70  1135.00  1111.95  1119.94  1811510.0\n",
       "10  2019-05-30  1120.15  1126.80  1115.90  1121.41   904419.0\n",
       "11  2019-05-31  1105.64  1113.40  1103.35  1106.50  1579481.0\n",
       "12  2019-06-03  1066.93  1067.00  1027.03  1038.74  4844480.0\n",
       "13  2019-06-04  1044.49  1058.44  1036.03  1054.49  3025564.0\n",
       "14  2019-06-05  1055.00  1056.81  1033.00  1044.64  2349436.0\n",
       "15  2019-06-06  1046.21  1050.00  1035.51  1047.76  1451026.0\n",
       "16  2019-06-07  1054.28  1073.43  1051.15  1068.37  2191357.0\n",
       "17  2019-06-10  1077.00  1094.84  1075.28  1082.76  1423928.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "ts = TimeSeries(key='D0D213LZDE18R8MB',  output_format='pandas')\n",
    "\n",
    "data, meta_data = ts.get_daily('GOOGL')\n",
    "data.reset_index(level=0, inplace=True)\n",
    "\n",
    "# Filter for only the dates needed\n",
    "google_stock = data[data.date > '2019-05-14'].reset_index(drop=True)\n",
    "google_stock.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "google_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "ts = TimeSeries(key='D0D213LZDE18R8MB',  output_format='pandas')\n",
    "\n",
    "stock_tables = ['netflix_stock', 'disney_stock', 'amazon_stock', 'google_stock']\n",
    "stock = ['NFLX', 'DIS', 'AMZN', 'GOOGL']\n",
    "i = 0\n",
    "for table in stock_tables:\n",
    "    data, meta_data = ts.get_daily(stock[i])\n",
    "    data.reset_index(level=0, inplace=True)\n",
    "    data = data[data.date > '2019-05-14'].reset_index(drop=True)\n",
    "    data.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "    data['Company'] = stock[i]\n",
    "    data.to_sql(name = table, con = conn, index = False)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
